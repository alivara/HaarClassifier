{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a240689-c821-4cdd-9cfb-1f69a99352fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "# from scipy import ndimage\n",
    "# import imageio\n",
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91930a91-c6fd-450f-b029-100e45ebf350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('train')\n",
    "# os.mkdir('/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/U')\n",
    "# os.mkdir('/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/D')\n",
    "\n",
    "# for i in os.listdir('/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2'):\n",
    "#     if i[0] == 'c':\n",
    "#         os.symlink('/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/'+i, '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/U/'+i)\n",
    "#     else:\n",
    "#         os.symlink('/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/'+i, '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/D/'+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07c97e-e546-4ddf-99a4-96d0f6175ec4",
   "metadata": {},
   "source": [
    "# First to save\n",
    "Source: \"https://stackoverflow.com/questions/47826730/how-to-save-resized-images-using-imagedatagenerator-and-flow-from-directory-in-k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b53e4b-a4b4-421a-9749-3bbffd5dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "#                                 height_shift_range=0.1,shear_range=0.15, \n",
    "#                                 zoom_range=0.1,channel_shift_range = 10, horizontal_flip=True)\n",
    "\n",
    "# # main image path\n",
    "# Path(\"path/to/folder\").iterdir()\n",
    "# images_path_ = ['/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/IMG_0303.jpg','/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/IMG_0304.jpg']\n",
    "# # image_path = 'C:/Users/Darshil/gitly/Deep-Learning/MyProjects/CNN_Keras/test_augment/caty.jpg'\n",
    "# for image_path in images_path:\n",
    "#     for i,j,k,m,n in [[1,2,3,4,5],[6,7,8,9,10]]:\n",
    "#         datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "#                                 height_shift_range=0.1,shear_range=0.15, \n",
    "#                                 zoom_range=0.1,channel_shift_range = 10, horizontal_flip=True)\n",
    "#         for path in Path(image_path).iterdir():\n",
    "#             image = np.expand_dims(imageio.imread(path), 0)\n",
    "\n",
    "#             # where to save the image \n",
    "#             save_here = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2'\n",
    "\n",
    "#             # Fit the original image\n",
    "#             datagen.fit(image)\n",
    "\n",
    "#             # save the generated image\n",
    "#             for x, val in zip(datagen.flow(image,                    #image we chose\n",
    "#                     save_to_dir=save_here,     #this is where we figure out where to save\n",
    "#                      save_prefix='aug',        # it will save the images as 'aug_0912' some number for every new augmented image\n",
    "#                     save_format='jpg'),range(10)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fbebe-e01d-45f6-8355-77e3b04812fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd5fb39-31ef-40c2-8a46-6f1df388f210",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\"\n",
    "'''\n",
    "\n",
    "\n",
    "def image_generator(rotation,zoom,main_path,save_path):\n",
    "    '''\n",
    "    Generate the Images\n",
    "    \n",
    "    rotation_range: 'Int. Degree range for random rotations'.\n",
    "    zoom_range: 'Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]'.\n",
    "    main_path: Directory of the main images.\n",
    "    save_path: where to save the created images.\n",
    "    \n",
    "    \"created images have size of target_size=(100, 100) and format: jpg\"\n",
    "    '''\n",
    "    # train_datagen = ImageDataGenerator(rotation_range=rotation,brightness_range=None,zoom_range=zoom,dtype=None)\n",
    "    #                 # featurewise_center=False,# samplewise_center=False,\n",
    "    #                 # featurewise_std_normalization=False,\n",
    "    #                 # samplewise_std_normalization=False,\n",
    "    #                 # zca_whitening=False,\n",
    "    #                 # zca_epsilon=1e-06,\n",
    "    #                 # rotation_range=rotation,\n",
    "    #                 # width_shift_range=0.0,\n",
    "    #                 # height_shift_range=0.0,\n",
    "    #                 # channel_shift_range=0.0,\n",
    "    #                 # fill_mode='nearest',\n",
    "    #                 # cval=0.0,\n",
    "    #                 # horizontal_flip=False,\n",
    "    #                 # vertical_flip=False,\n",
    "    #                 # rescale=None,\n",
    "    #                 # preprocessing_function=None,\n",
    "    #                 # data_format=None,\n",
    "    #                 # validation_split=0.0,\n",
    "    #                 # interpolation_order=1,\n",
    "    #                 # shear_range=0.0,\n",
    "    # train_generator = train_datagen.flow_from_directory('/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2',  # this is the target directory\n",
    "    #                                                     target_size=(100, 100),  # all images will be resized to 100*100\n",
    "    #                                                     class_mode='binary',\n",
    "    #                                                     batch_size = 25,\n",
    "    #                                                     save_to_dir= '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/',\n",
    "    #                                                     save_format= 'jpg')\n",
    "    \n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255,rotation_range=rotation,zoom_range=zoom)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(main_path,  # this is the target directory\n",
    "                                                        target_size=(224, 224),  # all images will be resized to 224x224\n",
    "                                                        batch_size=16,\n",
    "                                                        save_to_dir= save_path,\n",
    "                                                        save_format= 'jpg',\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "    \n",
    "    \n",
    "#     # show the generated images\n",
    "#     x, y = train_generator.next()\n",
    "\n",
    "#     plt.figure(figsize=(9, 9))\n",
    "#     for i, (img, label) in enumerate(zip(x, y)):\n",
    "#         plt.subplot(4, 4, i+1)\n",
    "#         if label == 1:\n",
    "#             plt.title('D')\n",
    "#         else:\n",
    "#             plt.title('U')\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img, interpolation=\"nearest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e6ad8-9bc1-4783-a757-0c3a90f4b6a9",
   "metadata": {},
   "source": [
    "## rename the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd3a3eb0-c7e7-4ecc-8a16-c6df102f16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "def rename_file(path):\n",
    "    os.getcwd()\n",
    "    for i, filename in enumerate(os.listdir(path)):\n",
    "        os.rename(path + filename, path + 'image' + \"_\" + str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf1477-8789-4082-9ff6-eeaf4012a456",
   "metadata": {},
   "source": [
    "## Read and creating images with opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4feecbb8-8067-495f-a18e-c0d1d4b9d322",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "module 'cv2' has no attribute 'imread'\n",
      "1\n",
      "module 'cv2' has no attribute 'imread'\n",
      "2\n",
      "module 'cv2' has no attribute 'imread'\n",
      "3\n",
      "module 'cv2' has no attribute 'imread'\n",
      "4\n",
      "module 'cv2' has no attribute 'imread'\n",
      "5\n",
      "module 'cv2' has no attribute 'imread'\n",
      "6\n",
      "module 'cv2' has no attribute 'imread'\n",
      "7\n",
      "module 'cv2' has no attribute 'imread'\n",
      "8\n",
      "module 'cv2' has no attribute 'imread'\n",
      "9\n",
      "module 'cv2' has no attribute 'imread'\n",
      "10\n",
      "module 'cv2' has no attribute 'imread'\n",
      "11\n",
      "module 'cv2' has no attribute 'imread'\n",
      "12\n",
      "module 'cv2' has no attribute 'imread'\n",
      "13\n",
      "module 'cv2' has no attribute 'imread'\n",
      "14\n",
      "module 'cv2' has no attribute 'imread'\n",
      "15\n",
      "module 'cv2' has no attribute 'imread'\n",
      "16\n",
      "module 'cv2' has no attribute 'imread'\n",
      "17\n",
      "module 'cv2' has no attribute 'imread'\n",
      "18\n",
      "module 'cv2' has no attribute 'imread'\n",
      "19\n",
      "module 'cv2' has no attribute 'imread'\n",
      "20\n",
      "module 'cv2' has no attribute 'imread'\n",
      "21\n",
      "module 'cv2' has no attribute 'imread'\n",
      "22\n",
      "module 'cv2' has no attribute 'imread'\n",
      "23\n",
      "module 'cv2' has no attribute 'imread'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "def store_raw_images(path):\n",
    "#     neg_images_link = '//image-net.org/api/text/imagenet.synset.geturls?wnid=n00523513'   \n",
    "#     neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
    "    pic_num = 1\n",
    "    \n",
    "#     if not os.path.exists('neg'):\n",
    "#         os.makedirs('neg')\n",
    "#     import cv2\n",
    "#     import glob\n",
    "\n",
    "#     images = [cv2.imread(file) for file in glob.glob('path/to/files/*.jpg')]\n",
    "    \n",
    "    for i, filename in enumerate(os.listdir(path)):\n",
    "        try:\n",
    "            print(i)\n",
    "            # urllib.request.urlretrieve(i, \"neg/\"+str(pic_num)+\".jpg\")\n",
    "            \n",
    "            # try to read image with opencv\n",
    "            # img = cv2.imread(\"neg/\"+str(pic_num)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.imread(path + filename, path + 'image' + \"_\" + str(i) + \".jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # should be larger than samples / pos pic (so we can place our image on it)\n",
    "            resized_image = cv2.resize(img, (100, 100))\n",
    "            # resized_image = cv2.resize(img)\n",
    "            cv2.imwrite(path + filename, path + 'image' + \"_\" + str(i) + \".jpg\",resized_image)\n",
    "            pic_num += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))  \n",
    "\n",
    "path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/pos_generated/'\n",
    "store_raw_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec487ac-160d-4ce5-8b28-f8c53f6e860f",
   "metadata": {},
   "source": [
    "## find ugly images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ce074-ddd3-451b-a7b0-66fa31910a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_uglies():\n",
    "#     match = False\n",
    "#     for file_type in ['neg']:\n",
    "#         for img in os.listdir(file_type):\n",
    "#             for ugly in os.listdir('uglies'):\n",
    "#                 try:\n",
    "#                     current_image_path = str(file_type)+'/'+str(img)\n",
    "#                     ugly = cv2.imread('uglies/'+str(ugly))\n",
    "#                     question = cv2.imread(current_image_path)\n",
    "#                     if ugly.shape == question.shape and not(np.bitwise_xor(ugly,question).any()):\n",
    "#                         print('That is one ugly pic! Deleting!')\n",
    "#                         print(current_image_path)\n",
    "#                         os.remove(current_image_path)\n",
    "#                 except Exception as e:\n",
    "#                     print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848c92f-5dc2-462c-89a5-2c5a5104855e",
   "metadata": {},
   "source": [
    "## neg images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ea3cccf-3f3c-4a72-a596-28e4a617d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/neg/'\n",
    "os.getcwd()\n",
    "for i, filename in enumerate(os.listdir(neg_path)):\n",
    "    os.rename(neg_path + filename, neg_path + 'image' + \"_\" + str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "591c1ebe-39ff-405d-94e6-7c63006af876",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "module 'cv2' has no attribute 'imread'\n",
      "1\n",
      "module 'cv2' has no attribute 'imread'\n",
      "2\n",
      "module 'cv2' has no attribute 'imread'\n",
      "3\n",
      "module 'cv2' has no attribute 'imread'\n",
      "4\n",
      "module 'cv2' has no attribute 'imread'\n",
      "5\n",
      "module 'cv2' has no attribute 'imread'\n",
      "6\n",
      "module 'cv2' has no attribute 'imread'\n",
      "7\n",
      "module 'cv2' has no attribute 'imread'\n",
      "8\n",
      "module 'cv2' has no attribute 'imread'\n",
      "9\n",
      "module 'cv2' has no attribute 'imread'\n",
      "10\n",
      "module 'cv2' has no attribute 'imread'\n",
      "11\n",
      "module 'cv2' has no attribute 'imread'\n",
      "12\n",
      "module 'cv2' has no attribute 'imread'\n",
      "13\n",
      "module 'cv2' has no attribute 'imread'\n",
      "14\n",
      "module 'cv2' has no attribute 'imread'\n",
      "15\n",
      "module 'cv2' has no attribute 'imread'\n",
      "16\n",
      "module 'cv2' has no attribute 'imread'\n",
      "17\n",
      "module 'cv2' has no attribute 'imread'\n",
      "18\n",
      "module 'cv2' has no attribute 'imread'\n",
      "19\n",
      "module 'cv2' has no attribute 'imread'\n",
      "20\n",
      "module 'cv2' has no attribute 'imread'\n",
      "21\n",
      "module 'cv2' has no attribute 'imread'\n",
      "22\n",
      "module 'cv2' has no attribute 'imread'\n",
      "23\n",
      "module 'cv2' has no attribute 'imread'\n"
     ]
    }
   ],
   "source": [
    "def store_raw_images():\n",
    "    neg_images_link = '//image-net.org/api/text/imagenet.synset.geturls?wnid=n07942152'   \n",
    "    neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
    "    pic_num = 953\n",
    "    \n",
    "    if not os.path.exists('neg'):\n",
    "        os.makedirs('neg')\n",
    "        \n",
    "    \n",
    "\n",
    "path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/neg/'\n",
    "store_raw_images()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb4a30-29a3-42bf-a142-efbb122b286b",
   "metadata": {},
   "source": [
    "## create the descriptor file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00abe5b-8d80-4ed5-b3a0-9b5cb9b213c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_n_neg():\n",
    "    for file_type in ['neg']:\n",
    "        \n",
    "        for img in os.listdir(file_type):\n",
    "\n",
    "            if file_type == 'pos':\n",
    "                line = file_type+'/'+img+' 1 0 0 50 50\\n'\n",
    "                with open('info.dat','a') as f:\n",
    "                    f.write(line)\n",
    "            elif file_type == 'neg':\n",
    "                line = file_type+'/'+img+'\\n'\n",
    "                with open('bg.txt','a') as f:\n",
    "                    f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17adab71-2e06-4591-9d4d-99b174bfc61f",
   "metadata": {},
   "source": [
    "## Run Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821592e-2527-4e50-9011-d713960dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Generate Images\n",
    "main_path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/pos/'\n",
    "save_path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/pos_generated/'\n",
    "\n",
    "for i in [22.5,45,67.5,90] :\n",
    "    for j in [.2,.4,.6]:\n",
    "        image_generator(i,j,main_path,save_path)\n",
    "\n",
    "# rename the files\n",
    "path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/pos_generated/'\n",
    "rename_file(path)\n",
    "\n",
    "# Read and creating images with opencv\n",
    "path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/pos_generated/'\n",
    "store_raw_images(path)\n",
    "\n",
    "# rename the files\n",
    "path = '/Users/alivarastehranjbar/Nextcloud/HaarClassifier/images_2/neg/'\n",
    "rename_file(path)\n",
    "\n",
    "# # Find ugly images\n",
    "# find_uglies()\n",
    "\n",
    "# Neg images\n",
    "store_raw_images(path)\n",
    "\n",
    "# Create the descriptor file\n",
    "create_pos_n_neg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc358673-d3d7-4a25-abce-14c34f132a66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## lets find opencv_createsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350fe16-1b33-422f-82dd-850ee1abb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv_createsamples -img watch5050.jpg -bg bg.txt -info info/info.lst -pngoutput info -maxxangle 0.5 -maxyangle 0.5 -maxzangle 0.5 -num 1950\n",
    "# opencv_createsamples -info info/info.lst -num 1950 -w 20 -h 20 -vec positives.vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6f7b1-d6a8-404f-86a1-a102dc01ced4",
   "metadata": {},
   "source": [
    "## lets find opencv_traincascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c7ce8-4656-49fa-a13a-be68730b0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv_traincascade -data data -vec positives.vec -bg bg.txt -numPos 1800 -numNeg 900 -numStages 10 -w 20 -h 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827a636-45dd-4d36-8925-d7c010426824",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## opencv cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df19c11-4e7f-4357-8009-33ee6e711569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cv2 import VideoCapture\n",
    "# import cv2\n",
    "# cap = cv2.VideoCapture(0)\n",
    "    \n",
    "# while True: \n",
    "    \n",
    "#     ret,img=cap.read()\n",
    "    \n",
    "#     cv2.imshow('Video', img)\n",
    "    \n",
    "#     if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ef93c-4a95-484e-83f4-5c9a79207b82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Showing the output of Imagedatagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c608fe7-da97-43c2-a253-5267bfd9a32c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m9\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (img, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x, y)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = train_generator.next()\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "for i, (img, label) in enumerate(zip(x, y)):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    if label == 1:\n",
    "        plt.title('D')\n",
    "    else:\n",
    "        plt.title('U')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06983371-83d1-454a-8270-ed263d8b8629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
